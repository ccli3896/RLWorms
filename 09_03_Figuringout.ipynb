{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dm_env\n",
    "from dm_env import specs\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time # delay within program\n",
    "from math import *\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import nidaqmx # laser output\n",
    "from pyueye import ueye\n",
    "from pypyueye import Camera\n",
    "\n",
    "from improc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processed worm as Deepmind env (returns relevant angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ACTIONS = (0,1) # Light off or on.\n",
    "\n",
    "class Processed_Worm(dm_env.Environment):\n",
    "    \"\"\" \n",
    "    The environment for the worm where states are relevant angles only. \n",
    "    Observations are thus (deg, deg). Actions are binary on or off.\n",
    "    Rewards are projected travel distance along some input angle, relative to positive x-axis.\n",
    "    \n",
    "    Based on https://github.com/deepmind/dm_env/blob/master/examples/catch.py example.\n",
    "    \n",
    "    No termination.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, target, discount=0.5):\n",
    "        \"\"\"\n",
    "        Initializes the camera, light, worm starting point.\n",
    "        \"\"\"\n",
    "        self.discount = discount\n",
    "        self.target = target\n",
    "        self.templates, self.bodies = load_templates()\n",
    "        self.cam, self.task = init_instruments()\n",
    "        self.bgs = self.make_bgs()\n",
    "        self.bg = self.bgs[0] # Set the active background to the no-light one\n",
    "        \n",
    "        self.head, self.old_loc = find_ht(self.cam, self.bg, self.templates, self.bodies,runtime=5)\n",
    "        self.last_loc = self.old_loc\n",
    "    \n",
    "    def make_bgs(self, light_vec=[0,1], total_time=20):\n",
    "        \"\"\"Makes background images and stores in self\"\"\"\n",
    "        self.bgs = make_vec_bg(self.cam,self.task,light_vec,total_time=total_time)\n",
    "        \n",
    "    def test_cam(self,bg=None):\n",
    "        \"\"\"To check camera is working, with or without background subtraction\"\"\"\n",
    "        return grab_im(self.cam, bg)\n",
    "    \n",
    "    def check_ht(self):\n",
    "        \"\"\"\n",
    "        Run this function every few seconds to make sure HT orientation is correct\n",
    "        Returns True if switched.\n",
    "        \"\"\"\n",
    "        self.head, SWITCH = ht_quick(self.worm, self.old_loc)\n",
    "        self.old_loc = self.worm['loc']\n",
    "        return SWITCH\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Returns the first `TimeStep` of a new episode.\"\"\"\n",
    "        self.bg = self.bgs[0]\n",
    "        self.head, self.old_loc = find_ht(self.cam, self.bg, self.templates, self.bodies,runtime=5)\n",
    "        self.last_loc = self.old_loc\n",
    "        \n",
    "        return dm_env.restart(self.step(0).observation)\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Chooses action and returns a (step_type, reward, discount, observation)\"\"\"\n",
    "        img = grab_im(self.cam, self.bg)\n",
    "        worms = find_worms(img, self.templates, self.bodies, ref_pts=[self.head], num_worms=1)\n",
    "        \n",
    "        if worms is None:\n",
    "            # Returns nans if no worm is found or something went wrong\n",
    "            self.task.write(0)\n",
    "            self.bg = self.bgs[0]\n",
    "            return dm_env.transition(reward=0., observation=(np.nan, np.nan))\n",
    "        \n",
    "        # Find state\n",
    "        self.worm = worms[0]\n",
    "        body_dir = relative_angle(self.worm['body'], self.target)\n",
    "        head_body = relative_angle(self.worm['angs'][0], self.worm['body'])\n",
    "        \n",
    "        # Find reward\n",
    "        reward = proj(self.worm['loc']-self.last_loc, [np.cos(self.target*pi/180),-np.sin(self.target*pi/180)])\n",
    "        if np.isnan(reward) or np.abs(reward)>10:\n",
    "            reward = 0\n",
    "        \n",
    "        self.last_loc = self.worm['loc']\n",
    "        return dm_env.transition(reward=reward, discount=self.discount, \n",
    "                                 observation=np.array([body_dir, head_body], dtype=np.int16))\n",
    "\n",
    "    def observation_spec(self):\n",
    "        \"\"\"Returns the observation spec.\"\"\"\n",
    "        return specs.Array(shape=2, dtype=np.int16)\n",
    "\n",
    "    def action_spec(self):\n",
    "        \"\"\"Returns the action spec.\"\"\"\n",
    "        return specs.DiscreteArray(\n",
    "            dtype=int, num_values=len(_ACTIONS), name=\"action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unprocessed worm (returns cropped images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ACTIONS = (0,1) # Light off or on.\n",
    "\n",
    "class Just_a_Worm(dm_env.Environment):\n",
    "    \"\"\" \n",
    "    The environment for the worm where states are cropped worm images.\n",
    "    Observations are grayscale images. Actions are binary on or off.\n",
    "    Rewards are projected travel distance along some input angle, relative to positive x-axis.\n",
    "    \n",
    "    No termination.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, target, discount=0.5):\n",
    "        \"\"\"\n",
    "        Initializes the camera, light, worm starting point.\n",
    "        \"\"\"\n",
    "        self.discount = discount\n",
    "        self.target = target\n",
    "        self.cam, self.task = init_instruments()\n",
    "        self.bgs = self.make_bgs()\n",
    "        self.bg = self.bgs[0] # Set the active background to the no-light one\n",
    "        \n",
    "        img = grab_im(self.cam, self.bg)\n",
    "        worms = find_worm_only(img)\n",
    "        \n",
    "        if worms is None:\n",
    "            # Returns nans if no worm is found or something went wrong\n",
    "            print('Error: No worm found')\n",
    "            return\n",
    "        \n",
    "        self.worm = worms[0]\n",
    "        self.last_loc = self.worm['loc']\n",
    "    \n",
    "    def make_bgs(self, light_vec=[0,1], total_time=20):\n",
    "        \"\"\"Makes background images and stores in self\"\"\"\n",
    "        self.bgs = make_vec_bg(self.cam,self.task,light_vec,total_time=total_time)\n",
    "        \n",
    "    def test_cam(self,bg=None):\n",
    "        \"\"\"To check camera is working, with or without background subtraction\"\"\"\n",
    "        return grab_im(self.cam, bg)\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Returns the first `TimeStep` of a new episode.\"\"\"\n",
    "        self.bg = self.bgs[0]\n",
    "        self.last_loc = self.worm['loc']\n",
    "        \n",
    "        return dm_env.restart(self.step(0).observation)\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Chooses action and returns a (step_type, reward, discount, observation)\"\"\"\n",
    "        img = grab_im(self.cam, self.bg)\n",
    "        worms = find_worm_only(img)\n",
    "        \n",
    "        if worms is None:\n",
    "            # Returns zeros if no worm is found or something went wrong\n",
    "            self.task.write(0)\n",
    "            self.bg = self.bgs[0]\n",
    "            return dm_env.transition(reward=0., observation=np.zeros(self.worm['img'].shape))\n",
    "        \n",
    "        self.worm = worms[0]\n",
    "        \n",
    "        # Find reward\n",
    "        reward = proj(self.worm['loc']-self.last_loc, [np.cos(self.target*pi/180),-np.sin(self.target*pi/180)])\n",
    "        if np.isnan(reward) or np.abs(reward)>10:\n",
    "            reward = 0\n",
    "        \n",
    "        self.last_loc = self.worm['loc']\n",
    "        return dm_env.transition(reward=reward, discount=self.discount, \n",
    "                                 observation=worm['img'])\n",
    "\n",
    "    def observation_spec(self):\n",
    "        \"\"\"Returns the observation spec.\"\"\"\n",
    "        return specs.BoundedArray(shape=(61,61), dtype=uint8, minimum=0, maximum=255)\n",
    "\n",
    "    def action_spec(self):\n",
    "        \"\"\"Returns the action spec.\"\"\"\n",
    "        return specs.DiscreteArray(\n",
    "            dtype=int, num_values=len(_ACTIONS), name=\"action\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:r903] *",
   "language": "python",
   "name": "conda-env-r903-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
