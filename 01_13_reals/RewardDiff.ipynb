{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting performances using reward differences only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import model_based_agent as mba \n",
    "import worm_env as we \n",
    "import ensemble_mod_env as eme\n",
    "\n",
    "from improc import *\n",
    "import utils as ut\n",
    "import tab_agents as tab\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_diff_method(\n",
    "    collection_eps = 3,\n",
    "    frac_on = 1/2,\n",
    "    eval_on_list = [1/2,1/3,1/4],\n",
    "    collection_ep_time = 600, # in seconds. Must be a multiple of worm_ep_len\n",
    "    eval_ep_time = 120, # in seconds. Also must be multiple of worm_ep_len\n",
    "    worm_ep_len = 120, # in seconds\n",
    "    init_df = None, # with folder \n",
    "):\n",
    "    '''\n",
    "    Function output:\n",
    "    Saves all trajectories for collection and eval episodes. \n",
    "    collect{i}.pkl for former and mod{i}_{eval frac ind}.pkl is the model after ep i.\n",
    "    eval{i}_{eval frac ind}.pkl for latter\n",
    "\n",
    "    1. Collects data with light on frac_on of the time.\n",
    "    2. Evaluates reward difference policy with various amounts of light penalty given\n",
    "        by eval_on_list. \n",
    "    '''\n",
    "\n",
    "    folder = './Data/Run'+datetime.now().strftime('%d-%m-%H-%M')+'/'\n",
    "    if os.path.isdir(folder):\n",
    "        os.rmdir(folder)\n",
    "    os.mkdir(folder)\n",
    "\n",
    "    # Initialize objects\n",
    "    dh = mba.DataHandler()\n",
    "    if init_df is not None:\n",
    "        dh.load_df(init_df)\n",
    "    worm = we.ProcessedWorm(0,ep_len=worm_ep_len) \n",
    "\n",
    "    ant = tab.Q_Alpha_Agent()\n",
    "    runner = mba.WormRunner(ant,worm,act_spacing=1)\n",
    "        # act_spacing here is only for eval episodes\n",
    "\n",
    "\n",
    "    for ce in range(collection_eps):\n",
    "        # Collecting random data\n",
    "        #############################\n",
    "        fname = folder+f'collect{ce}.pkl'\n",
    "        if collection_ep_time%worm_ep_len != 0:\n",
    "            raise ValueError('Collection_ep_time is not a multiple of worm_ep_len')\n",
    "        print(f'Collecting randoms {ce}')\n",
    "        mba.get_init_traj(fname, worm, int(collection_ep_time/worm_ep_len), rand_probs=[1-frac_on,frac_on])\n",
    "        dh.add_dict_to_df([fname],reward_ahead=10,timestep_gap=1,prev_act_window=3,jump_limit=100)\n",
    "\n",
    "        # Find RDiff matrix and collect eval episodes\n",
    "        #############################\n",
    "        cam,task = init_instruments()\n",
    "        for i,ev in enumerate(eval_on_list):\n",
    "            print(f'Finding policy')\n",
    "            mset = eme.ModelSet(1,frac=1,lp_frac=ev)\n",
    "            mset.make_models(dh,{'lambda':.1,'iters':10})\n",
    "            # Save model\n",
    "            mname = folder+f'mod{ce}_{i}.pkl'\n",
    "            with open(mname,'wb') as f:\n",
    "                pickle.dump(mset.models[0],f)\n",
    "\n",
    "            rdiff = np.sign(mset.models[0]['reward_on'][:,:,0]-mset.models[0]['reward_off'][:,:,0])\n",
    "            runner.agent.Qtab[:,0] = np.zeros(144)\n",
    "            runner.agent.Qtab[:,1] = rdiff.flatten()\n",
    "            ename = folder+f'eval{ce}_{i}.pkl'\n",
    "            print(f'Running eval ep {i}')\n",
    "            runner.eval_ep(cam,task,ename,eval_eps=int(eval_ep_time/worm_ep_len))\n",
    "        cam.exit()\n",
    "        task.write(0)\n",
    "        task.close()\n",
    "    dh.save_dfs('totaldf.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting randoms 0\n",
      "Warning: when changing pixelclock at runtime, you may need to update the fps and exposure parameters\n",
      "Warning: Specified fps (20.00) not in possible range: [7.40, 14.92]. fps has been set to 14.92.\n",
      "19 sec \t\t\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccli3\\Documents\\Research\\20_09_07_NewPC\\RLWorms\\01_13_reals\\improc.py:196: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  centers.append(np.array([np.sum(np.arange(im_sz)*sumx) / np.sum(sumx), np.sum(np.arange(im_sz)*sumy) / np.sum(sumy)]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: when changing pixelclock at runtime, you may need to update the fps and exposure parameters\n",
      "Warning: Specified fps (20.00) not in possible range: [7.40, 14.92]. fps has been set to 14.92.\n",
      "Finding policy\n",
      "On model 0\n",
      "Penalty -0.3514723660769161\n",
      "Running eval ep 0\n",
      "Finding policy\n",
      "On model 0\n",
      "Penalty -0.24156639483478126\n",
      "Running eval ep 1\n",
      "Finding policy\n",
      "On model 0\n",
      "Penalty -0.10944554070572998\n",
      "Running eval ep 2\n",
      "Collecting randoms 1\n",
      "Warning: when changing pixelclock at runtime, you may need to update the fps and exposure parameters\n",
      "Warning: Specified fps (20.00) not in possible range: [7.40, 14.92]. fps has been set to 14.92.\n",
      "Warning: when changing pixelclock at runtime, you may need to update the fps and exposure parameters\n",
      "Warning: Specified fps (20.00) not in possible range: [7.40, 14.92]. fps has been set to 14.92.\n",
      "Finding policy\n",
      "On model 0\n",
      "Penalty -0.013946934423879398\n",
      "Running eval ep 0\n",
      "Finding policy\n",
      "On model 0\n",
      "Penalty 0.21265360672329292\n",
      "Running eval ep 1\n",
      "Finding policy\n",
      "On model 0\n",
      "Penalty 0.32225000150634786\n",
      "Running eval ep 2\n",
      "Collecting randoms 2\n",
      "Warning: when changing pixelclock at runtime, you may need to update the fps and exposure parameters\n",
      "Warning: Specified fps (20.00) not in possible range: [7.40, 14.92]. fps has been set to 14.92.\n",
      "Warning: when changing pixelclock at runtime, you may need to update the fps and exposure parameters\n",
      "Warning: Specified fps (20.00) not in possible range: [7.40, 14.92]. fps has been set to 14.92.\n",
      "Finding policy\n",
      "On model 0\n",
      "Penalty -0.10981718058631884\n",
      "Running eval ep 0\n",
      "Finding policy\n",
      "On model 0\n",
      "Penalty 0.17212397880456454\n",
      "Running eval ep 1\n",
      "Finding policy\n",
      "On model 0\n",
      "Penalty 0.3196292657845537\n",
      "Running eval ep 2\n",
      "19 sec \t\t\t\r"
     ]
    }
   ],
   "source": [
    "reward_diff_method(    \n",
    "    collection_eps = 3,\n",
    "    frac_on = 1/2,\n",
    "    eval_on_list = [1/2,1/3,1/4],\n",
    "    collection_ep_time = 600, # in seconds. Must be a multiple of worm_ep_len\n",
    "    eval_ep_time = 120, # 0 in seconds. Also must be multiple of worm_ep_len\n",
    "    worm_ep_len = 120, #00 in seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emergency light shut-off\n",
    "import nidaqmx\n",
    "task = nidaqmx.Task()\n",
    "task.ao_channels.add_ao_voltage_chan(\"Dev1/ao0\")\n",
    "task.write(0)\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlkit",
   "language": "python",
   "name": "rlkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
