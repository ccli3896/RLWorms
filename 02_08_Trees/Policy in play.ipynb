{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "from scipy.stats import norm\n",
    "\n",
    "# import utils as ut\n",
    "# from improc import *\n",
    "# import policy_time as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R file: get_posterior.R should be running simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First worm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_pol_collection(\n",
    "    folder, #'./Data/Pol03_02_0/'\n",
    "    init_episodes=1,\n",
    "    ):\n",
    "\n",
    "    # Fixed parameters\n",
    "    ep=0\n",
    "    params = {\n",
    "        'reward_ahead': 30,\n",
    "        'timestep_gap': 1,\n",
    "        'prev_act_window': 3,\n",
    "        'jump_limit': 100,\n",
    "    }\n",
    "\n",
    "\n",
    "    # Collect initial random trajectory\n",
    "    worm = we.ProcessedWorm(0,ep_len=300) # Each worm episode will be several minutes long\n",
    "    fnames=[]\n",
    "    fnames.append(f'{folder}traj{ep}.pkl')\n",
    "    pt.get_init_traj(fname[0], worm, init_episodes, act_rate=3)\n",
    "\n",
    "\n",
    "    # Load trajectory in a data handler object as a df. Save for R.\n",
    "    dh = pt.DataHandler(params=params)\n",
    "    dh.add_dict_to_df(fnames)\n",
    "    dh.df = pt.change_reward_ahead(dh.df,params['reward_ahead'],jump_limit=params['jump_limit'])\n",
    "    dh.save_dfs(f'{folder}df{ep}.pkl')\n",
    "    pt.save_for_R(dh.df, f'{folder}traj{ep}.npy')\n",
    "\n",
    "\n",
    "    # Now R script will run and create a file that we will sit and wait for.\n",
    "    bart_f = f'{folder}sbart{ep}.npy'\n",
    "    while not os.path.exists(bart_f):\n",
    "        time.sleep(1)\n",
    "    # Now that the file exists, we get the highest entropy states and decide to explore them more\n",
    "    # in the future.\n",
    "    post = np.load(bart_f,allow_pickle=True)\n",
    "    probs, ents = pt.bart2pols(post)\n",
    "    np.save(f'{folder}probs{ep}.npy',probs,allow_pickle=True)\n",
    "    np.save(f'{folder}ents{ep}.npy',ents,allow_pickle=True)\n",
    "    \n",
    "def gen_pol_collection(\n",
    "    worm_id, # Should not be 0\n",
    "    \n",
    "    # All parameters below this should be same as in first_pol_collection() function.\n",
    "    folder, #'./Data/Pol03_02_0/'\n",
    "    init_episodes=1,\n",
    "    tot_eps=5,\n",
    "    base_sampling=.1, # All states will have a base sampling rate of 10% (5% light on)\n",
    "    samp_states_decay=5, # tau such that perc light will be on is 1/2*[(1-base)e^(-ep/tau)+base]\n",
    "    ):\n",
    "    \n",
    "    # Fixed parameters\n",
    "    params = {\n",
    "        'reward_ahead': 30,\n",
    "        'timestep_gap': 1,\n",
    "        'prev_act_window': 3,\n",
    "        'jump_limit': 100,\n",
    "    }\n",
    "    \n",
    "    # Load entropies and dataframe from previous run    \n",
    "    curr_ep = 1+worm_id*tot_eps\n",
    "    dh = pt.DataHandler()\n",
    "    dh.load_df(f'{folder}df{curr_ep-1}.pkl')\n",
    "    ents = np.load(f'{folder}ents{curr_ep-1}.npy',allow_pickle=True)\n",
    "\n",
    "    for ep in np.arange(tot_eps)+curr_ep:\n",
    "        # Create a list of states to search based on entropy and cutoff.\n",
    "        # alpha is the proportion of time we are sampling. alpha*.5 is proportion of time light is on.\n",
    "        alpha = (1-base_sampling)*np.exp(-ep/samp_states_decay)+base_sampling\n",
    "        counts = pt.get_counts(dh.df)\n",
    "        sampling_probs = pt.make_sprobs_cutoff(ents,alpha,counts,base_sampling)\n",
    "\n",
    "\n",
    "        # Get new data\n",
    "        fnames[0] = f'{folder}traj{ep}.pkl'\n",
    "        pt.do_sampling_traj(sampling_probs, fnames[0], worm, episodes, act_rate=3)\n",
    "\n",
    "\n",
    "        # Save for R in addition to old data \n",
    "        dh_n = pt.DataHandler(params=params)\n",
    "        dh_n.add_dict_to_df(fnames)\n",
    "        dh_n.df = pt.change_reward_ahead(dh_n.df,params['reward_ahead'],jump_limit=params['jump_limit'])\n",
    "        dh_n.df = dh_n.df.append(dh.df, ignore_index=True)\n",
    "        dh_n.save_dfs(f'{folder}df{ep}.pkl')\n",
    "        pt.save_for_R(dh_n.df, f'{folder}traj{ep}.npy')    \n",
    "        dh = dh_n\n",
    "\n",
    "\n",
    "        # Wait for R script to run\n",
    "        bart_f = f'{folder}sbart{ep}.npy'\n",
    "        while not os.path.exists(bart_f):\n",
    "            time.sleep(1)\n",
    "        # Get the probabilities and entropies \n",
    "        post = np.load(bart_f,allow_pickle=True)\n",
    "        probs, ents = pt.bart2pols(post)\n",
    "        np.save(f'{folder}probs{ep}.npy',probs,allow_pickle=True)\n",
    "        np.save(f'{folder}ents{ep}.npy',ents,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r919",
   "language": "python",
   "name": "r919"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
